#! /bin/env python
# coding:utf-8

#
# Read tweets in json fils, and create a corpus for each json.
#

#import create_corpus as cc
import mecab_inc as mi

import numpy as np
import random
import sys
reload(sys)
sys.setdefaultencoding("utf-8")

file_name = 'tweets/new_A.txt'
#file_name = 'tweets/test_data.txt'
k = 10 #number of clusters

def create_corpus(file_name):
    global W,C
    W = {}
    C = {}
    for line in open(file_name,'r'):
        text = mi.clean_text(line)
        WL = mi.create_word_list(text)
        WL = sorted(set(WL))
        for i in xrange(len(WL)):
            if WL[i] in W:
                W[WL[i]] += 1
            else:
                W[WL[i]] = 1
            for j in xrange(i+1,len(WL)):
                if WL[i] in C:
                    if WL[j] in C[WL[i]]:
                        C[WL[i]][WL[j]] += 1
                    else:
                        C[WL[i]][WL[j]] = 1
                else:
                    C[WL[i]] = {WL[j]:1}

def f(i,j):
    try:
        a = C[Words[i]][Words[j]]
        return a*1.0/(W[Words[i]]+W[Words[j]]-a)
    except:
        return 0

def create_table():
    #単語Word[i]とWord[j]の共起度table[i][j]=table[j][i]を生成
    global table
    table = [[None]*len(Words) for i in xrange(len(Words))]
    for i in xrange(len(Words)):
        table[i][i] = 1
        for j  in xrange(i+1,len(Words)):
            table[i][j] = f(i,j)
            table[j][i] = table[i][j]

def centroid(mem_ship):
    V = [np.array([0]*len(Words)) for i in xrange(k)]
    count = [0]*k
    for i in xrange(len(Words)):
        count[mem_ship[i]] += 1
        V[mem_ship[i]] += np.array(table[i])
    V = [V[i]*1.0/np.array(count[i]) for i in xrange(k)]
    return V

def argmin(i,V):
    min_i = 0
    min = sum((V[0]-np.array(table[i]))**2)
    for j in xrange(1,k):
        tmp = sum((V[j]-np.array(table[i]))**2)
        if tmp == min:
            print tmp,'warn!'
        if tmp < min:
            min_i = j
            min = tmp
    return min_i

def update(V):
    new_mem_ship  = [None]*len(Words)
    for i in xrange(len(Words)):
        new_mem_ship[i] = argmin(i,V)
    return new_mem_ship
            
def k_means():
    while True:
        mem_ship = list(np.random.randint(0,k,len(Words)))
        #mem_ship = [random.randrange(k) for i in range(len(Words))]
        if len(set(mem_ship)) == k:
            break
    r = 0
    while True:
        r+=1
        #print mem_ship
        V = centroid(mem_ship)
        #########中心の合体処理
        #print V
        #########
        new_mem_ship = update(V)
        if mem_ship == new_mem_ship:
            break
        else:
            mem_ship = new_mem_ship

    print 'クラスタ数:',k
    print '繰り返し回数:',r
    return mem_ship
    

if __name__ == '__main__':
    create_corpus(file_name)
    Words = sorted(W) #dict W -> list Words
    create_table()
    mem_ship = k_means()

    #for i in xrange(len(Words)):
    #    print Words[i]+':',mem_ship[i]

    for i in xrange(k):
        print 'cluster num =',i
        for j in xrange(len(Words)):
            if mem_ship[j] == i and W[Words[j]] > 2:
                print Words[j]+':',W[Words[j]],
        print ''
                
    
